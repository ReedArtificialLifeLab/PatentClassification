Howdy,

Sorry to be getting back to you a bit late. I didn't get around to pulling all the data before the weekend.

I've attached the 2010 H&P paper. See section 3A starting on page 1433 for details on corpus filtering. In particular,

"Our full sample of 10-Ks from 1997–2008 comprises 68,302 observa-
tions; this declines to 63,875 when we exclude firms without valid Com-
pustat data, firms with nonpositive sales, or firms with assets of less than
$1 million. This declines further to 50,673 if we additionally require 1 year
of lagged Compustat data and exclude financial firms (SIC codes in the
range 6000–6999)."

I've also linked the corpus in CSV with headers id, text where each id is a string of the form [sic]_[cik]_[date]_[name] and each text is the 10-K filing for that year after preprocessing. The ciks are unique to each firm. The sics are a classification. The file is kinda big (~6.9gb) so depending on your computer you may need to break it up.

Finally, you'll need compustat data. I've attached a cik to gvkey mapping.

The most convenient function would take a CSV in the format I've described (along with gvkey data) and return a CSV in the same format. Then Ananthan and James can just throw the corpus into their pipelines without having to think about it.

Cheers,
Tobias
